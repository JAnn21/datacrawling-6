{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e5579aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     종암동\n",
       "1    길음1동\n",
       "2     석관동\n",
       "3     안암동\n",
       "4     동선동\n",
       "Name: 행정동명, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_excel('./data/성북구_행정동별_생활인구수.xlsx')\n",
    "data_top5 = data.head(5)\n",
    "targets = []\n",
    "targets = data_top5['행정동명']\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a20fe986",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "성북구 생활인구수 top5동 음식집 데이터 수집\n",
      "\n",
      "종암동 음식집(카카오맵) 데이터 수집 시작\n",
      "종암동 1 번째 페이지 완료\n",
      "종암동 2 번째 페이지 완료\n",
      "종암동 3 번째 페이지 완료\n",
      "종암동 4 번째 페이지 완료\n",
      "종암동 5 번째 페이지 완료\n",
      "종암동 6 번째 페이지 완료\n",
      "종암동 7 번째 페이지 완료\n",
      "종암동 8 번째 페이지 완료\n",
      "종암동 9 번째 페이지 완료\n",
      "종암동 10 번째 페이지 완료\n",
      "종암동 완료================\n",
      "\n",
      "길음1동 음식집(카카오맵) 데이터 수집 시작\n",
      "길음1동 1 번째 페이지 완료\n",
      "길음1동 2 번째 페이지 완료\n",
      "길음1동 3 번째 페이지 완료\n",
      "길음1동 4 번째 페이지 완료\n",
      "길음1동 5 번째 페이지 완료\n",
      "길음1동 6 번째 페이지 완료\n",
      "길음1동 7 번째 페이지 완료\n",
      "길음1동 8 번째 페이지 완료\n",
      "길음1동 9 번째 페이지 완료\n",
      "길음1동 10 번째 페이지 완료\n",
      "길음1동 완료================\n",
      "\n",
      "석관동 음식집(카카오맵) 데이터 수집 시작\n",
      "석관동 1 번째 페이지 완료\n",
      "석관동 2 번째 페이지 완료\n",
      "석관동 3 번째 페이지 완료\n",
      "석관동 4 번째 페이지 완료\n",
      "석관동 5 번째 페이지 완료\n",
      "석관동 6 번째 페이지 완료\n",
      "석관동 7 번째 페이지 완료\n",
      "석관동 8 번째 페이지 완료\n",
      "석관동 9 번째 페이지 완료\n",
      "석관동 10 번째 페이지 완료\n",
      "석관동 완료================\n",
      "\n",
      "안암동 음식집(카카오맵) 데이터 수집 시작\n",
      "안암동 1 번째 페이지 완료\n",
      "안암동 2 번째 페이지 완료\n",
      "안암동 3 번째 페이지 완료\n",
      "안암동 4 번째 페이지 완료\n",
      "안암동 5 번째 페이지 완료\n",
      "안암동 6 번째 페이지 완료\n",
      "안암동 7 번째 페이지 완료\n",
      "안암동 8 번째 페이지 완료\n",
      "안암동 9 번째 페이지 완료\n",
      "안암동 10 번째 페이지 완료\n",
      "안암동 완료================\n",
      "\n",
      "동선동 음식집(카카오맵) 데이터 수집 시작\n",
      "동선동 1 번째 페이지 완료\n",
      "동선동 2 번째 페이지 완료\n",
      "동선동 3 번째 페이지 완료\n",
      "동선동 4 번째 페이지 완료\n",
      "동선동 5 번째 페이지 완료\n",
      "동선동 6 번째 페이지 완료\n",
      "동선동 7 번째 페이지 완료\n",
      "동선동 8 번째 페이지 완료\n",
      "동선동 9 번째 페이지 완료\n",
      "동선동 10 번째 페이지 완료\n",
      "동선동 완료================\n",
      "\n",
      "\n",
      "전체 데이터 수집 완료\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup     \n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "print('성북구 생활인구수 top5동 음식집 데이터 수집')\n",
    "print()\n",
    "\n",
    "for target in targets:\n",
    "    print(target, '음식집(카카오맵) 데이터 수집 시작')\n",
    "\n",
    "    url=\"https://map.kakao.com/\"\n",
    "    path = \"./data/chromedriver.exe\"\n",
    "    driver = webdriver.Chrome(path)\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    searchbox = driver.find_element_by_xpath(\"//input[@id='search.keyword.query']\")\n",
    "    searchbox.send_keys(target + \" 맛집\")\n",
    "\n",
    "    searchbutton = driver.find_element_by_xpath(\"//button[@id='search.keyword.submit']\")\n",
    "    driver.execute_script(\"arguments[0].click();\", searchbutton)\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    df = pd.DataFrame(columns=['업종','가게이름','평가점수','평가인원', '리뷰개수', '주소', \"전화\", \"링크주소\"])\n",
    "\n",
    "    crawdata= soup.find_all(\"li\",\"PlaceItem clickArea\")\n",
    "\n",
    "    for shop in range(len(crawdata)):\n",
    "\n",
    "        li= soup.find_all(\"li\",\"PlaceItem clickArea\")[shop]\n",
    "        sector = li.find(\"span\",\"subcategory clickable\").text \n",
    "        name = li.find(\"a\",\"link_name\").text               \n",
    "        point = li.find(\"em\",\"num\").text                   \n",
    "        person = li.find(\"a\",\"numberofscore\").text[:-1] \n",
    "        reviews2 = li.find(\"a\",\"review\").text[3:]         \n",
    "        add1 = li.find(\"div\",\"addr\")\n",
    "        add = add1.find_all(\"p\")[0].text                    \n",
    "        phone1 = li.find(\"div\",\"contact clickArea\")\n",
    "        phone = phone1.find(\"span\").text                         \n",
    "        b_link = li.find_all(\"a\")[7].get('href')\n",
    "\n",
    "        df=df.append({'업종':sector,'가게이름':name,'평가점수':point,'평가인원':person, \n",
    "                      '리뷰개수':reviews2, '주소':add, \"전화\":phone, \"링크주소\":b_link}, ignore_index=True)\n",
    "\n",
    "    print(target+\" 1 번째 페이지 완료\")\n",
    "\n",
    "    # 더보기 버튼이 있을경우 더보기 버튼 누르기 (2번)\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        element1 = driver.find_element_by_id(\"info.search.place.more\")\n",
    "        ActionChains(driver).move_to_element(element1).click(element1).perform()\n",
    "        ActionChains(driver).move_to_element(element1).click(element1).perform()\n",
    "\n",
    "        try:\n",
    "            for nextpage in range(3,6,1):\n",
    "                time.sleep(1)\n",
    "                # 2페이지~5페이지\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                crawdata= soup.find_all(\"li\",\"PlaceItem clickArea\")[1]\n",
    "\n",
    "                for shop in range(len(crawdata)):\n",
    "                    selltime=\"\"\n",
    "                    li= soup.find_all(\"li\",\"PlaceItem clickArea\")[shop]\n",
    "                    sector = li.find(\"span\",\"subcategory clickable\").text\n",
    "                    name = li.find(\"a\",\"link_name\").text\n",
    "                    point = li.find(\"em\",\"num\").text \n",
    "                    person = li.find(\"a\",\"numberofscore\").text[:-1] \n",
    "                    reviews2 = li.find(\"a\",\"review\").text[3:]\n",
    "                    add1 = li.find(\"div\",\"addr\")\n",
    "                    add = add1.find_all(\"p\")[0].text\n",
    "                    phone1 = li.find(\"div\",\"contact clickArea\")\n",
    "                    phone = phone1.find(\"span\").text\n",
    "                    b_link = li.find_all(\"a\")[7].get('href') \n",
    "\n",
    "                    df=df.append({'업종':sector,'가게이름':name,'평가점수':point,'평가인원':person, \n",
    "                                  '리뷰개수':reviews2, '주소':add, \"전화\":phone, \"링크주소\":b_link}, ignore_index=True)\n",
    "\n",
    "                print( target, nextpage-1, \"번째 페이지 완료\")\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "                # 다음 페이지 버튼\n",
    "                element1 = driver.find_element_by_id(\"info.search.page.no{}\".format(nextpage))\n",
    "                ActionChains(driver).move_to_element(element1).click(element1).perform()\n",
    "        except:\n",
    "            pass\n",
    "        print(target+\" 5 번째 페이지 완료\")    \n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # 다음 목록 >\n",
    "        element1 = driver.find_element_by_id(\"info.search.page.next\")\n",
    "        ActionChains(driver).move_to_element(element1).click(element1).perform()\n",
    "\n",
    "        # 6페이지~10페이지\n",
    "        for nextpage in range(2,7,1):\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            crawdata= soup.find_all(\"li\",\"PlaceItem clickArea\")[1]\n",
    "            \n",
    "            for shop in range(len(crawdata)):\n",
    "                selltime=\"\"\n",
    "                li= soup.find_all(\"li\",\"PlaceItem clickArea\")[shop]\n",
    "                sector = li.find(\"span\",\"subcategory clickable\").text \n",
    "                name = li.find(\"a\",\"link_name\").text              \n",
    "                point = li.find(\"em\",\"num\").text                \n",
    "                person = li.find(\"a\",\"numberofscore\").text[:-1]    \n",
    "                reviews2 = li.find(\"a\",\"review\").text[3:]     \n",
    "                add1 = li.find(\"div\",\"addr\")\n",
    "                add = add1.find_all(\"p\")[0].text                   \n",
    "                phone1 = li.find(\"div\",\"contact clickArea\")\n",
    "                phone = phone1.find(\"span\").text                  \n",
    "                b_link = li.find_all(\"a\")[7].get('href')\n",
    "\n",
    "                df=df.append({'업종':sector,'가게이름':name,'평가점수':point,'평가인원':person, \n",
    "                              '리뷰개수':reviews2, '주소':add, \"전화\":phone, \"링크주소\":b_link}, ignore_index=True)\n",
    "\n",
    "            print( target, nextpage+4, \"번째 페이지 완료\")\n",
    "            time.sleep(1)\n",
    "\n",
    "            # 다음 페이지 버튼\n",
    "            element1 = driver.find_element_by_id(\"info.search.page.no{}\".format(nextpage))\n",
    "            ActionChains(driver).move_to_element(element1).click(element1).perform()\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    savepath = \"./data/\"\n",
    "    df.to_csv(savepath+target+\" 음식집 카카오맵 데이터 크롤링.csv\", index = False, mode='w', encoding = 'utf-8-sig')\n",
    "    print(target+' 완료'+'================')\n",
    "    print()\n",
    "    driver.close()\n",
    "    \n",
    "print()\n",
    "print('전체 데이터 수집 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ce4d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
